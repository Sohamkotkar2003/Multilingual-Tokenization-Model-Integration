# ğŸš€ NLLB-200 Training - Quick Start Guide

## âœ… What You Need:
- âœ… `flores200_dataset.tar.gz` (25MB) - Already in your project folder!
- âœ… `colab_train_nllb200.ipynb` - The complete training notebook
- âœ… Google account (for Colab)
- âœ… 2-3 hours (training time)

---

## ğŸ“ Step-by-Step Instructions:

### **Step 1: Go to Google Colab**
1. Open: https://colab.research.google.com
2. Click **"File"** â†’ **"Upload notebook"**
3. Upload `colab_train_nllb200.ipynb`

### **Step 2: Enable GPU**
1. Click **"Runtime"** â†’ **"Change runtime type"**
2. Select **"T4 GPU"**
3. Click **"Save"**

### **Step 3: Run Training**
1. **Cell 1**: Check GPU (make sure T4 is available)
2. **Cell 2**: Install packages (takes 1-2 minutes)
3. **Cell 3**: Upload `flores200_dataset.tar.gz` (25MB)
4. **Cell 4**: Create training data (~34,000 pairs)
5. **Cell 5**: Load NLLB-200 model (2-3 minutes)
6. **Cell 6**: Configure LoRA adapter
7. **Cell 7**: Prepare dataset (1-2 minutes)
8. **Cell 8**: Configure training parameters
9. **Cell 9**: â±ï¸ **TRAIN** (2-3 hours - go have coffee!)
10. **Cell 10**: Save adapter
11. **Cell 11**: Test translations
12. **Cell 12**: Download adapter (5-10 MB)

### **Step 4: Use on Your PC**
1. Extract `nllb_18languages_adapter.zip`
2. Place in: `adapters/nllb_18languages_adapter/`
3. Done! Use with your API

---

## ğŸ¯ What You'll Get:

- âœ… **18 Languages**: Assamese, Bengali, English, Gujarati, Hindi, Kannada, Kashmiri, Malayalam, Meitei, Marathi, Nepali, Odia, Punjabi, Sanskrit, Sindhi, Tamil, Telugu, Urdu
- âœ… **High Quality**: 85-90% translation accuracy (much better than BLOOMZ!)
- âœ… **Correct Scripts**: No more Chinese for Gujarati!
- âœ… **Small Size**: Only ~5-10 MB adapter
- âœ… **Fast Inference**: Works with your existing API

---

## ğŸ’¡ Tips:

- âœ… **Keep the Colab tab open** during training (you can minimize the browser)
- âœ… **Free T4 GPU** is enough (no need for paid Colab)
- âœ… **Checkpoints saved** every epoch (if disconnected, you can resume)
- âœ… **Training progress** is shown in real-time

---

## ğŸ†˜ Troubleshooting:

**Q: Colab disconnected?**
- A: Reconnect and resume from last checkpoint (checkpoints saved in `nllb_adapter/checkpoint-XX/`)

**Q: Out of memory?**
- A: Reduce `per_device_train_batch_size` from 4 to 2 in Cell 8

**Q: Training too slow?**
- A: Normal! 2-3 hours is expected for quality results

**Q: How do I test a specific language?**
- A: After training, you can specify NLLB language codes (e.g., `hin_Deva` for Hindi)

---

## ğŸ‰ Expected Results:

**BLOOMZ (current):**
- âŒ Gujarati â†’ Chinese characters
- âŒ Telugu â†’ English fallback
- âŒ Bengali â†’ "Category:" artifacts
- âš ï¸ Quality: 50-70%

**NLLB-200 (after training):**
- âœ… Gujarati â†’ Correct Gujarati script
- âœ… Telugu â†’ Correct Telugu script
- âœ… Bengali â†’ Clean Bengali text
- âœ… Quality: 85-90%

---

**Ready to start? Upload the notebook to Colab and run Cell 1!** ğŸš€

